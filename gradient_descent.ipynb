{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Gradient Descent is an algorithm that is used to optimize the cost function or the error of the model. It is used to find the minimum value of error possible in your model"
      ],
      "metadata": {
        "id": "ha3XNxg_wZ1n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Ju_bkCb8ZNC",
        "outputId": "fb760e09-278c-4f3b-d834-d544623f61c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/kaggle\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os \n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/drive/My Drive/kaggle'\n",
        "%cd /content/drive/My Drive/kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import statistics as st\n",
        "import math\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import math"
      ],
      "metadata": {
        "id": "0w7qMT5E-Aru"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/kaggle/test_scores.csv\")\n",
        "df.head(15)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "N6zGkiDZAxJ7",
        "outputId": "5b70de02-e6da-4d59-c118-64a5e15d9071"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     name  math  cs\n",
              "0   david    92  98\n",
              "1   laura    56  68\n",
              "2  sanjay    88  81\n",
              "3     wei    70  80\n",
              "4    jeff    80  83\n",
              "5   aamir    49  52\n",
              "6  venkat    65  66\n",
              "7   virat    35  30\n",
              "8  arthur    66  68\n",
              "9    paul    67  73"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d5b7ec7-aefc-4134-9cd2-0179b1a09cf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>math</th>\n",
              "      <th>cs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>david</td>\n",
              "      <td>92</td>\n",
              "      <td>98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>laura</td>\n",
              "      <td>56</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sanjay</td>\n",
              "      <td>88</td>\n",
              "      <td>81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>wei</td>\n",
              "      <td>70</td>\n",
              "      <td>80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jeff</td>\n",
              "      <td>80</td>\n",
              "      <td>83</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>aamir</td>\n",
              "      <td>49</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>venkat</td>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>virat</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>arthur</td>\n",
              "      <td>66</td>\n",
              "      <td>68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>paul</td>\n",
              "      <td>67</td>\n",
              "      <td>73</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d5b7ec7-aefc-4134-9cd2-0179b1a09cf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d5b7ec7-aefc-4134-9cd2-0179b1a09cf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d5b7ec7-aefc-4134-9cd2-0179b1a09cf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r = linear_model.LinearRegression()\n",
        "r.fit(df[['math']],df.cs)\n",
        "r.coef_,r.intercept_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxlT1ZyOqEV1",
        "outputId": "d6c4dc6d-510f-4a72-bc50-11651e8d3688"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.01773624]), 1.9152193111569034)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(x,y):\n",
        "  m_curr = b_curr = 0\n",
        "  cost_prev = 0\n",
        "  n = len(x)\n",
        "  iterations = 1000;\n",
        "  learning_rate = 0.01\n",
        "  plt.scatter(x,y,color='pink',marker='*')\n",
        "\n",
        "  for i in range(iterations):\n",
        "    yp = m_curr*x +b_curr\n",
        "    cost_prev = 0\n",
        "    cost= sum(val**2 for val in (y-yp))\n",
        "    plt.plot(x,yp,color='green')\n",
        "    md = -(2/n)*x*(y- yp)\n",
        "    bd = -(2/n)*(y-yp)\n",
        "    m_curr = m_curr - learning_rate*md\n",
        "    b_curr= b_curr - learning_rate*bd\n",
        "    if math.isclose(cost, cost_prev, rel_tol=1e-20):\n",
        "            break\n",
        "    cost_prev = cost\n",
        "    format(m_curr,b_curr,cost, i)\n",
        "        \n"
      ],
      "metadata": {
        "id": "MePTYEzhlsn_"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array(df.math)\n",
        "y = np.array(df['cs'])"
      ],
      "metadata": {
        "id": "d10PfbY2pG_S"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_using_sklean():\n",
        "    df = pd.read_csv(\"test_scores.csv\")\n",
        "    r = LinearRegression()\n",
        "    r.fit(df[['math']],df.cs)\n",
        "    return r.coef_, r.intercept_"
      ],
      "metadata": {
        "id": "V54LH-J3usXX"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AB98ozRKsD-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " The math.isclose() function is used to check whether two given values are close to each other. The closeness of the two values is determined according to the given absolute and relative tolerances. The function returns\n",
        "\n",
        "True, if the values are close.\n",
        "False, if they are not close.***\n"
      ],
      "metadata": {
        "id": "rjTBM5P_v83G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "format func will write the paarameters in given format\n",
        "as here 1e-20"
      ],
      "metadata": {
        "id": "YtWKcBbkwt6t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' Good students always try to solve exercise on their own first and then look at the ready made solution\n",
        "    I know you are an awesome student !! :)\n",
        "    Hence you will look into this code only after you have done your due diligence.\n",
        "    If you are not an awesome student who is full of laziness then only you will come here\n",
        "    without writing single line of code on your own. In that case anyways you are going to\n",
        "    face my anger with fire and fury !!!\n",
        "'''\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import math\n",
        "\n",
        "def predict_using_sklean():\n",
        "    df = pd.read_csv(\"test_scores.csv\")\n",
        "    r = LinearRegression()\n",
        "    r.fit(df[['math']],df.cs)\n",
        "    return r.coef_, r.intercept_\n",
        "\n",
        "def gradient_descent(x,y):\n",
        "    m_curr = 0\n",
        "    b_curr = 0\n",
        "    iterations = 100\n",
        "    n = len(x)\n",
        "    learning_rate = 0.0002\n",
        "\n",
        "    cost_previous = 0\n",
        "\n",
        "    for i in range(iterations):\n",
        "        y_predicted = m_curr * x + b_curr\n",
        "        cost = (1/n)*sum([value**2 for value in (y-y_predicted)])\n",
        "        md = -(2/n)*sum(x*(y-y_predicted))\n",
        "        bd = -(2/n)*sum(y-y_predicted)\n",
        "        m_curr = m_curr - learning_rate * md\n",
        "        b_curr = b_curr - learning_rate * bd\n",
        "        if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
        "            break\n",
        "        cost_previous = cost\n",
        "        print (\"m {}, b {}, cost {}, iteration {}\".format(m_curr,b_curr,cost, i))\n",
        "        \n",
        "\n",
        "    return m_curr, b_curr\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    df = pd.read_csv(\"test_scores.csv\")\n",
        "    x = np.array(df.math)\n",
        "    y = np.array(df.cs)\n",
        "\n",
        "    m, b = gradient_descent(x,y)\n",
        "    print(\"Using gradient descent function: Coef {} Intercept {}\".format(m, b))\n",
        "\n",
        "    m_sklearn, b_sklearn = predict_using_sklean()\n",
        "    print(\"Using sklearn: Coef {} Intercept {}\".format(m_sklearn,b_sklearn))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXfmTef5vAag",
        "outputId": "32268ba0-c6ea-413a-d12f-4ac22c12cae1"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "m 1.9783600000000003, b 0.027960000000000002, cost 5199.1, iteration 0\n",
            "m 0.20975041279999962, b 0.0030470367999999894, cost 4161.482445460163, iteration 1\n",
            "m 1.7908456142986242, b 0.025401286955264, cost 3332.2237319269248, iteration 2\n",
            "m 0.37738163667530467, b 0.005499731626422651, cost 2669.4843523161976, iteration 3\n",
            "m 1.6409848166378898, b 0.023373894401807944, cost 2139.826383775145, iteration 4\n",
            "m 0.5113514173939655, b 0.0074774305434828076, cost 1716.5264071567592, iteration 5\n",
            "m 1.5212165764726306, b 0.021771129698498662, cost 1378.2272007804495, iteration 6\n",
            "m 0.6184191426785134, b 0.009075514323270572, cost 1107.8601808918404, iteration 7\n",
            "m 1.4254981563597626, b 0.020507724625171385, cost 891.7842215178443, iteration 8\n",
            "m 0.7039868810749315, b 0.010370210797388455, cost 719.0974036421305, iteration 9\n",
            "m 1.3490002310389348, b 0.01951553325074733, cost 581.0869686205, iteration 10\n",
            "m 0.7723719384951477, b 0.01142244086408669, cost 470.7897237271261, iteration 11\n",
            "m 1.2878632281408475, b 0.018740093691150705, cost 382.6407204862143, iteration 12\n",
            "m 0.8270246840299113, b 0.012280892197750798, cost 312.1924801681589, iteration 13\n",
            "m 1.2390025969113474, b 0.01813788028359247, cost 255.89060022344475, iteration 14\n",
            "m 0.8707026352388424, b 0.012984475742007832, cost 210.89442007737276, iteration 15\n",
            "m 1.1999531799587442, b 0.01767410753812916, cost 174.93369813849728, iteration 16\n",
            "m 0.9056095862354473, b 0.013564288926616264, cost 146.19406878727372, iteration 17\n",
            "m 1.168744835939885, b 0.017320975066834464, cost 123.2255001796068, iteration 18\n",
            "m 0.9335067981503328, b 0.014045184660493999, cost 104.86913418555842, iteration 19\n",
            "m 1.1438030378387343, b 0.017056264940052912, cost 90.1988172376793, iteration 20\n",
            "m 0.9558018619881088, b 0.014447025263025912, cost 78.4743720801518, iteration 21\n",
            "m 1.123869431612398, b 0.016862220700598438, cost 69.10425278659366, iteration 22\n",
            "m 0.9736197173740411, b 0.014785684599634922, cost 61.61569883880534, iteration 23\n",
            "m 1.1079383470620547, b 0.016724651477560692, cost 55.63088241716976, iteration 24\n",
            "m 0.9878594103778675, b 0.015073848983471565, cost 50.84784543555072, iteration 25\n",
            "m 1.0952060576414993, b 0.016632215998581557, cost 47.02526451581355, iteration 26\n",
            "m 0.9992394540800741, b 0.015321657252001263, cost 43.970275232370476, iteration 27\n",
            "m 1.0850302291522722, b 0.01657585037608088, cost 41.528741309884765, iteration 28\n",
            "m 1.0083340805074807, b 0.015537212312981736, cost 39.57747781519814, iteration 29\n",
            "m 1.0768975113455124, b 0.01654831079689666, cost 38.01803597157669, iteration 30\n",
            "m 1.0156022129971571, b 0.01572698996942581, cost 36.77173601363096, iteration 31\n",
            "m 1.0703976372937574, b 0.016543808042154003, cost 35.775697470042715, iteration 32\n",
            "m 1.0214106207634122, b 0.015896165650447946, cost 34.97966658555935, iteration 33\n",
            "m 1.0652027237396349, b 0.016557715397389393, cost 34.34348081266759, iteration 34\n",
            "m 1.0260524239108442, b 0.016048875532907396, cost 33.83504244613808, iteration 35\n",
            "m 1.0610507280390304, b 0.01658633521579648, cost 33.42869916198312, iteration 36\n",
            "m 1.0297618825473565, b 0.016188425228507268, cost 33.103949752366304, iteration 37\n",
            "m 1.0577322270335765, b 0.0166267123567505, cost 32.84440975547639, iteration 38\n",
            "m 1.0327262161686235, b 0.016317456565470633, cost 32.636984792143764, iteration 39\n",
            "m 1.0550798507922887, b 0.016676485086818824, cost 32.47120990063734, iteration 40\n",
            "m 1.035095049650491, b 0.016438080879614143, cost 32.33872153636954, iteration 41\n",
            "m 1.052959838111218, b 0.01673376592060118, cost 32.23283559672576, iteration 42\n",
            "m 1.036987962438417, b 0.016551985539901195, cost 32.14821018063812, iteration 43\n",
            "m 1.0512652877114044, b 0.01679704638933073, cost 32.08057606773955, iteration 44\n",
            "m 1.0385005218215662, b 0.016660519083126275, cost 32.02652131866401, iteration 45\n",
            "m 1.0499107646303472, b 0.016865120932420777, cost 31.983319128693804, iteration 46\n",
            "m 1.0397091046950075, b 0.01676475925312493, cost 31.94879024926364, iteration 47\n",
            "m 1.0488279896772978, b 0.01693702607197308, cost 31.921193035921274, iteration 48\n",
            "m 1.0406747510877237, b 0.016865567377366896, cost 31.899135575212195, iteration 49\n",
            "m 1.047962394467687, b 0.017011991801351975, cost 31.881505456930224, iteration 50\n",
            "m 1.0414462438827428, b 0.016963631824454838, cost 31.86741364845402, iteration 51\n",
            "m 1.0472703682240316, b 0.01708940273517817, cost 31.85614963940047, iteration 52\n",
            "m 1.0420625701139212, b 0.017059502735137972, cost 31.847145593458148, iteration 53\n",
            "m 1.046717057433117, b 0.017168767060599943, cost 31.839947698713402, iteration 54\n",
            "m 1.0425548880219075, b 0.017153619779162816, cost 31.83419327097573, iteration 55\n",
            "m 1.0462746073431242, b 0.01724969172330578, cost 31.829592454870966, iteration 56\n",
            "m 1.0429480991153375, b 0.017246334338408182, cost 31.825913599447194, iteration 57\n",
            "m 1.0459207565770121, b 0.017331862596311, cost 31.82297157043309, iteration 58\n",
            "m 1.0432621045542085, b 0.017337927235534713, cost 31.82061840945363, iteration 59\n",
            "m 1.0456377139546258, b 0.017415028630952047, cost 31.81873586892226, iteration 60\n",
            "m 1.0435128092451273, b 0.017428622902632068, cost 31.81722944596486, iteration 61\n",
            "m 1.0454112608545958, b 0.01749898919044121, cost 31.816023614361388, iteration 62\n",
            "m 1.0437129243091645, b 0.017518600704730235, cost 31.81505801393808, iteration 63\n",
            "m 1.0452300338265001, b 0.017583583926907467, cost 31.81428440514876, iteration 64\n",
            "m 1.0438726084101126, b 0.01760800398949262, cost 31.81366423519171, iteration 65\n",
            "m 1.0450849512581242, b 0.017668684691178615, cost 31.813166692862268, iteration 66\n",
            "m 1.043999980300792, b 0.017696947319685068, cost 31.812767154001268, iteration 67\n",
            "m 1.0449687551708302, b 0.017754189067120032, cost 31.812445939105075, iteration 68\n",
            "m 1.0441015284474728, b 0.017785522253328603, cost 31.81218732041362, iteration 69\n",
            "m 1.0448756450247292, b 0.017840015204310798, cost 31.811978728380467, iteration 70\n",
            "m 1.0441824383996428, b 0.01787380196316831, cost 31.81181011748764, iteration 71\n",
            "m 1.0448009850576234, b 0.01792609768834459, cost 31.811673459407757, iteration 72\n",
            "m 1.0442468544222752, b 0.017961844928529556, cost 31.811562337942128, iteration 73\n",
            "m 1.0447410703917646, b 0.01801238424039495, cost 31.811471625297237, iteration 74\n",
            "m 1.0442980885910158, b 0.018049697885830843, cost 31.811397223366267, iteration 75\n",
            "m 1.044692940107559, b 0.01809883307952457, cost 31.811335856963026, iteration 76\n",
            "m 1.0443387879000003, b 0.018137398186618782, cost 31.811284908575193, iteration 77\n",
            "m 1.044654227853013, b 0.018185410814656123, cost 31.811242286300104, iteration 78\n",
            "m 1.04437106781358, b 0.01822497568209775, cost 31.811206318299767, iteration 79\n",
            "m 1.044623042451559, b 0.018272090759846052, cost 31.811175668449643, iteration 80\n",
            "m 1.0443966190001837, b 0.018312454229236455, cost 31.81114926892579, iteration 81\n",
            "m 1.044597872484431, b 0.018358851587859853, cost 31.81112626632863, iteration 82\n",
            "m 1.0444167926334849, b 0.018399852894440714, cost 31.811105978625633, iteration 83\n",
            "m 1.0445775100333783, b 0.018445676254116222, cost 31.811087860739732, iteration 84\n",
            "m 1.0444326685646632, b 0.01848718691552271, cost 31.81107147704813, iteration 85\n",
            "m 1.0445609897362342, b 0.0185325511367087, cost 31.81105647940329, iteration 86\n",
            "m 1.044445109805328, b 0.018574468470501836, cost 31.81104258956744, iteration 87\n",
            "m 1.044547540080427, b 0.01861946534911527, cost 31.811029585174346, iteration 88\n",
            "m 1.044454806070002, b 0.018661707292026614, cost 31.81101728851003, iteration 89\n",
            "m 1.0445365444770032, b 0.01870641019091935, cost 31.81100555754639, iteration 90\n",
            "m 1.0444623085750486, b 0.01874891115841746, cost 31.810994278775315, iteration 91\n",
            "m 1.0445275101511837, b 0.018793378708828794, cost 31.810983361481625, iteration 92\n",
            "m 1.0444680578498022, b 0.01883608628610563, cost 31.810972733166256, iteration 93\n",
            "m 1.044520043279852, b 0.018880365345844474, cost 31.810962335888206, iteration 94\n",
            "m 1.0444724059630832, b 0.01892323764326849, cost 31.810952123341476, iteration 95\n",
            "m 1.0445138291215608, b 0.0189673656608776, cost 31.810942058518464, iteration 96\n",
            "m 1.0444756342865145, b 0.01901036920048514, cost 31.810932111842874, iteration 97\n",
            "m 1.0445086161365338, b 0.01905437610466928, cost 31.81092225967744, iteration 98\n",
            "m 1.0444779676908766, b 0.01909748413105923, cost 31.81091248313143, iteration 99\n",
            "Using gradient descent function: Coef 1.0444779676908766 Intercept 0.01909748413105923\n",
            "Using sklearn: Coef [1.01773624] Intercept 1.9152193111569034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " if math.isclose(cost, cost_previous, rel_tol=1e-20):\n",
        "            break\n",
        "        cost_previous = cost\n",
        "        print (\"m {}, b {}, cost {}, iteration {}\".format(m_curr,b_curr,cost, i))\n",
        "        \n",
        "\n",
        "        this line was just to check all the iterations."
      ],
      "metadata": {
        "id": "3HUWiM4by1fs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gradient_descent(x,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w7_8JsFdxr2o",
        "outputId": "a96f6c01-5cdf-445e-ffa8-201a6617cc75"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1.9783600000000003, 0.027960000000000002)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_using_sklean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7p7feqVxuVP",
        "outputId": "d41f9be3-a94c-4836-f4ca-1c64f2f6cb4f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1.01773624]), 1.9152193111569034)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    }
  ]
}
